---
permalink: /research/
title: ""
excerpt: "Research"
author_profile: true

---

<font size=6><a href="https://github.com/bohanzhuang/model-quantization">QTool:</a></font>
This project provides abundant choices of quantization strategies (such as the quantization algoirthms, training schedules and empirical tricks) for quantizing the image classification neural networks into low bit counterparts. Associated projects demonstrate that this project can also benefit other computer vision tasks, such as object detection, segmentation and text parsing. Pretrained models are provided to show high standard of the code on achiving appealing quantization performance.



<font size=6><a href="https://pocketflow.github.io/dcp_learner/">DCP:</a></font>
Discrimination-aware channel pruning (DCP, Zhuang et al., 2018) introduces a group of additional discriminative losses into the network to be pruned, to find out which channels are really contributing to the discriminative power and should be preserved. After channel pruning, the number of input channels of each convolutional layer is reduced, so that the model becomes smaller and the inference speed can be improved.

